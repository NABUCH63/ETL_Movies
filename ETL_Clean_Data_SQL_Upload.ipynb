{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "from config import password\n",
    "# from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = 'Input'\n",
    "# Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia_movies.json'\n",
    "# Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add the clean movie function that takes in the argument, \"movie\".\n",
    "def clean_movie(movies):\n",
    "    movie = dict(movies)\n",
    "    alt_titles = {}\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key]= movie[key]\n",
    "            movie.pop(key)\n",
    "        if len(alt_titles) > 0:\n",
    "            movie['alt_titles'] = alt_titles\n",
    "            \n",
    "        def change_column_name(old_name, new_name):\n",
    "            if old_name in movie:\n",
    "                movie[new_name] = movie.pop(old_name)\n",
    "                \n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "    \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(*file):\n",
    "# 2. Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    for f in file:\n",
    "        if \"csv\" in f:\n",
    "            file_input = pd.read_csv(f, low_memory=False)\n",
    "            df = pd.DataFrame(file_input)\n",
    "        else:\n",
    "            with open(f, mode='r') as x:\n",
    "                file_input = json.load(x)\n",
    "                file_input1 = [i for i in file_input\n",
    "                if ('Director' in i or 'Directed by' in i)\n",
    "                    and ('imdb_link' in i) and ('No. of episodes' not in i)]\n",
    "                file_input2 = [clean_movie(movie) for movie in file_input1]\n",
    "            df = pd.DataFrame(file_input2)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for parsing budget column data\n",
    "def parse_dollars(x):\n",
    "    if type(x) != str:\n",
    "        return np.nan\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', x, flags=re.IGNORECASE):\n",
    "        x = re.sub(r'\\$|\\s*|[a-zA-Z]', '', x)\n",
    "        value = float(x) * 1000000\n",
    "        return value\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', x, flags=re.IGNORECASE):\n",
    "        x = re.sub(r'\\$|\\s*|[a-zA-Z]', '', x)\n",
    "        value = float(x) * 1000000000\n",
    "        return value\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illi?on)', x, flags=re.IGNORECASE):\n",
    "        x = re.sub(r'\\$|,', '', x)\n",
    "        value = float(x)\n",
    "        return value\n",
    "    else: \n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "    df[kaggle_column] = df.apply(\n",
    "        lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "        , axis=1)\n",
    "    df.drop(columns=wiki_column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute functions to load data in DataFrames, and to perform the initial \"clean\" function\n",
    "files_to_load = [wiki_file, kaggle_file, ratings_file]\n",
    "file_names = [\"wiki_movies_df\", \"kaggle_meta\", \"ratings\"]\n",
    "for x, y in zip(file_names, files_to_load):\n",
    "    globals()[x] = load_dataset(y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # clean IMDB data\n",
    "    # grab only the IMDB ID number from each entry\n",
    "    wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "    # drop dupicated from the IMDB ID column\n",
    "    wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "    # count the number of null values per column, and compare to the total. keep if sum is less than 90% of the total dataset\n",
    "    columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "    wiki_movies_df = wiki_movies_df[columns_to_keep]\n",
    "    # clean box office data\n",
    "    # drop null values from Box Office\n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    # convert to string values and filter based on regular expressions\n",
    "        # if a list, join values with a space, else keep original\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "        # define regex to capture the most common formats\n",
    "    form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "    form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illi?on)'\n",
    "        # replace hypens from value ranges with '$'\n",
    "    box_office = box_office.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "        # execute capture of both regex statements for the box_office column and apply the Parse_Dollars function\n",
    "    wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    # drop original Box office column\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    # clean budget data\n",
    "    # drop null values\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    # join lists with a space if a list is present, else keep the original value \n",
    "    budget = budget.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    # replace hyphen value ranges with a '$'\n",
    "    budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)\n",
    "    # remove bracketed references\n",
    "    budget = budget.str.replace(r'\\[\\d+\\]\\s*', '', regex=True)\n",
    "    # capture buget values based on the same regex used for box office values\n",
    "    wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "    # drop original column\n",
    "    wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "    # clean release date data\n",
    "    # drop null values and join lists if they are present, else keep value\n",
    "    release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    # define date formats as regex\n",
    "        # Month DD YYYY\n",
    "    date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{1,2},\\d{4}'\n",
    "        # YYYY (various separator) MM (various separator) DD\n",
    "    date_form_two = r'\\d{4}[,|.|-|\\:|\\\\|\\s|/]\\d{2}[,|.|-|\\:|\\\\|\\s|/]\\d{2}'\n",
    "        # Month YYYY\n",
    "    date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "        # YYYY\n",
    "    date_form_four = r'\\d{4}'\n",
    "    # capture release dates that contain the above regex, convert to datetime and auto identify date format\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)[0], infer_datetime_format=True)\n",
    "    # clean running time data\n",
    "    # drop null values and join lists if they exist, else keep original value\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    # capture only the number values for varying hour/min formats\n",
    "    running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    # convert the captured values to numeric formats, based on columns H|M|minutes(separate from first pair)\n",
    "    running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "    # calculate running time combining cols 1 and 2 (if not 0), else using 3\n",
    "    wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: float(row[0]*60 + row[1]) if row[2] == 0 else float(row[2]), axis=1)\n",
    "    # drop original column\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "    # Clean Kaggle data\n",
    "    # drop adult films, and grab those that are videos\n",
    "    kaggle_meta = kaggle_meta[kaggle_meta['adult'] == 'False'].drop('adult',axis='columns')\n",
    "    kaggle_meta['video'] = kaggle_meta['video'] == 'True'\n",
    "    # set budget column as integer\n",
    "    kaggle_meta['budget'] = kaggle_meta['budget'].astype(int)\n",
    "    # change ID column to numeric\n",
    "    kaggle_meta['id'] = pd.to_numeric(kaggle_meta['id'], errors='raise')\n",
    "    # change popularity to numeric\n",
    "    kaggle_meta['popularity'] = pd.to_numeric(kaggle_meta['popularity'], errors='raise')\n",
    "    # change release date to datetime\n",
    "    kaggle_meta['release_date'] = pd.to_datetime(kaggle_meta['release_date'])\n",
    "    # merge movies dataframe with kaggle data on movies df IMDB ID\n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_meta, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "    # change running time to float type\n",
    "    [float(x) for x in movies_df['running_time']]\n",
    "    # call function to fill in missing data\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "    # filer movies to specific columns\n",
    "    movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                   'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                   'genres','original_language','overview','spoken_languages','Country',\n",
    "                   'production_companies','production_countries','Distributor',\n",
    "                   'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                  ]]\n",
    "    # rename columns to specific\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                      'title_kaggle':'title',\n",
    "                      'url':'wikipedia_url',\n",
    "                      'budget_kaggle':'budget',\n",
    "                      'release_date_kaggle':'release_date',\n",
    "                      'Country':'country',\n",
    "                      'Distributor':'distributor',\n",
    "                      'Producer(s)':'producers',\n",
    "                      'Director':'director',\n",
    "                      'Starring':'starring',\n",
    "                      'Cinematography':'cinematography',\n",
    "                      'Editor(s)':'editors',\n",
    "                      'Writer(s)':'writers',\n",
    "                      'Composer(s)':'composers',\n",
    "                      'Based on':'based_on'\n",
    "                     }, axis='columns', inplace=True)\n",
    "    # count the number of ratings per movie by rating, rename to 'count', create table to show ID, and rating count\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "            .rename({'userId':'count'}, axis=1) \\\n",
    "            .pivot(index='movieId',columns='rating', values='count')\n",
    "    # convert ratings timestamp to datetime\n",
    "    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    # rename columns to represent rating value\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "    # fill empty counts with 0\n",
    "    rating_counts = rating_counts[[\"rating_0.5\", \"rating_1.0\", \"rating_1.5\", \"rating_2.0\", \"rating_2.5\", \"rating_3.0\", \"rating_3.5\", \"rating_4.0\", \"rating_4.5\", \"rating_5.0\"]].fillna(0)\n",
    "    # merge ratings with movies_df for final dataframe\n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')\n",
    "    for i in [\"rating_0.5\", \"rating_1.0\", \"rating_1.5\", \"rating_2.0\", \"rating_2.5\", \"rating_3.0\", \"rating_3.5\", \"rating_4.0\", \"rating_4.5\", \"rating_5.0\"]:\n",
    "        movies_with_ratings_df[i].fillna(0, inplace=True)\n",
    "    movies_with_ratings_df['belongs_to_collection'].fillna(\"No\", inplace=True)\n",
    "except Exception as error:\n",
    "    print(error)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>kaggle_id</th>\n",
       "      <th>title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>tagline</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>wikipedia_url</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>runtime</th>\n",
       "      <th>budget</th>\n",
       "      <th>...</th>\n",
       "      <th>rating_0.5</th>\n",
       "      <th>rating_1.0</th>\n",
       "      <th>rating_1.5</th>\n",
       "      <th>rating_2.0</th>\n",
       "      <th>rating_2.5</th>\n",
       "      <th>rating_3.0</th>\n",
       "      <th>rating_3.5</th>\n",
       "      <th>rating_4.0</th>\n",
       "      <th>rating_4.5</th>\n",
       "      <th>rating_5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0098987</td>\n",
       "      <td>9548</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>The Adventures of Ford Fairlane</td>\n",
       "      <td>Kojak. Columbo. Dirty Harry. Wimps.</td>\n",
       "      <td>No</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Adventures_o...</td>\n",
       "      <td>https://www.imdb.com/title/tt0098987/</td>\n",
       "      <td>104.0</td>\n",
       "      <td>49000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0098994</td>\n",
       "      <td>25501</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>After Dark, My Sweet</td>\n",
       "      <td>All they risked was everything.</td>\n",
       "      <td>No</td>\n",
       "      <td>https://en.wikipedia.org/wiki/After_Dark,_My_S...</td>\n",
       "      <td>https://www.imdb.com/title/tt0098994/</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0099005</td>\n",
       "      <td>11856</td>\n",
       "      <td>Air America</td>\n",
       "      <td>Air America</td>\n",
       "      <td>The few. The proud. The totally insane.</td>\n",
       "      <td>No</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Air_America_(film)</td>\n",
       "      <td>https://www.imdb.com/title/tt0099005/</td>\n",
       "      <td>112.0</td>\n",
       "      <td>35000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0099012</td>\n",
       "      <td>8217</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Alice</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alice_(1990_film)</td>\n",
       "      <td>https://www.imdb.com/title/tt0099012/</td>\n",
       "      <td>102.0</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0099018</td>\n",
       "      <td>25943</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>Almost an Angel</td>\n",
       "      <td>Who does he think he is?</td>\n",
       "      <td>No</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Almost_an_Angel</td>\n",
       "      <td>https://www.imdb.com/title/tt0099018/</td>\n",
       "      <td>95.0</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     imdb_id  kaggle_id                            title  \\\n",
       "0  tt0098987       9548  The Adventures of Ford Fairlane   \n",
       "1  tt0098994      25501             After Dark, My Sweet   \n",
       "2  tt0099005      11856                      Air America   \n",
       "3  tt0099012       8217                            Alice   \n",
       "4  tt0099018      25943                  Almost an Angel   \n",
       "\n",
       "                    original_title                                  tagline  \\\n",
       "0  The Adventures of Ford Fairlane      Kojak. Columbo. Dirty Harry. Wimps.   \n",
       "1             After Dark, My Sweet          All they risked was everything.   \n",
       "2                      Air America  The few. The proud. The totally insane.   \n",
       "3                            Alice                                      NaN   \n",
       "4                  Almost an Angel                 Who does he think he is?   \n",
       "\n",
       "  belongs_to_collection                                      wikipedia_url  \\\n",
       "0                    No  https://en.wikipedia.org/wiki/The_Adventures_o...   \n",
       "1                    No  https://en.wikipedia.org/wiki/After_Dark,_My_S...   \n",
       "2                    No   https://en.wikipedia.org/wiki/Air_America_(film)   \n",
       "3                    No    https://en.wikipedia.org/wiki/Alice_(1990_film)   \n",
       "4                    No      https://en.wikipedia.org/wiki/Almost_an_Angel   \n",
       "\n",
       "                               imdb_link  runtime      budget  ...  \\\n",
       "0  https://www.imdb.com/title/tt0098987/    104.0  49000000.0  ...   \n",
       "1  https://www.imdb.com/title/tt0098994/    114.0   6000000.0  ...   \n",
       "2  https://www.imdb.com/title/tt0099005/    112.0  35000000.0  ...   \n",
       "3  https://www.imdb.com/title/tt0099012/    102.0  12000000.0  ...   \n",
       "4  https://www.imdb.com/title/tt0099018/     95.0  25000000.0  ...   \n",
       "\n",
       "   rating_0.5 rating_1.0  rating_1.5  rating_2.0  rating_2.5 rating_3.0  \\\n",
       "0         0.0        0.0         0.0         0.0         0.0        0.0   \n",
       "1         0.0        0.0         0.0         0.0         0.0        0.0   \n",
       "2         0.0        0.0         0.0         0.0         0.0        0.0   \n",
       "3         0.0        0.0         0.0         0.0         0.0        0.0   \n",
       "4         3.0        0.0         3.0         2.0         5.0       26.0   \n",
       "\n",
       "  rating_3.5 rating_4.0 rating_4.5 rating_5.0  \n",
       "0        0.0        0.0        0.0        0.0  \n",
       "1        0.0        0.0        0.0        0.0  \n",
       "2        0.0        0.0        0.0        0.0  \n",
       "3        0.0        0.0        0.0        0.0  \n",
       "4       37.0       46.0       16.0       11.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20. Check that the wiki_movies_df DataFrame looks like this. \n",
    "movies_with_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb_id',\n",
       " 'kaggle_id',\n",
       " 'title',\n",
       " 'original_title',\n",
       " 'tagline',\n",
       " 'belongs_to_collection',\n",
       " 'wikipedia_url',\n",
       " 'imdb_link',\n",
       " 'runtime',\n",
       " 'budget',\n",
       " 'revenue',\n",
       " 'release_date',\n",
       " 'popularity',\n",
       " 'vote_average',\n",
       " 'vote_count',\n",
       " 'genres',\n",
       " 'original_language',\n",
       " 'overview',\n",
       " 'spoken_languages',\n",
       " 'country',\n",
       " 'production_companies',\n",
       " 'production_countries',\n",
       " 'distributor',\n",
       " 'producers',\n",
       " 'director',\n",
       " 'starring',\n",
       " 'cinematography',\n",
       " 'editors',\n",
       " 'writers',\n",
       " 'composers',\n",
       " 'based_on',\n",
       " 'rating_0.5',\n",
       " 'rating_1.0',\n",
       " 'rating_1.5',\n",
       " 'rating_2.0',\n",
       " 'rating_2.5',\n",
       " 'rating_3.0',\n",
       " 'rating_3.5',\n",
       " 'rating_4.0',\n",
       " 'rating_4.5',\n",
       " 'rating_5.0']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21. Check that wiki_movies_df DataFrame columns are correct. \n",
    "movies_with_ratings_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Chunk Done. 48.866738080978394 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Chunk Done. 47.790443658828735 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Chunk Done. 47.639814138412476 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Chunk Done. 47.94582724571228 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Chunk Done. 49.34446907043457 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Chunk Done. 48.45144557952881 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Chunk Done. 47.260180711746216 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Chunk Done. 46.02908897399902 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Chunk Done. 46.38875198364258 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Chunk Done. 53.09155035018921 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Chunk Done. 57.98240351676941 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Chunk Done. 49.533578395843506 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Chunk Done. 47.41750741004944 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Chunk Done. 55.98290514945984 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Chunk Done. 46.019994258880615 total seconds elapsed\n",
      "importing rows 15000000 to 16000000...Chunk Done. 46.38920974731445 total seconds elapsed\n",
      "importing rows 16000000 to 17000000...Chunk Done. 46.47827959060669 total seconds elapsed\n",
      "importing rows 17000000 to 18000000...Chunk Done. 46.19354224205017 total seconds elapsed\n",
      "importing rows 18000000 to 19000000...Chunk Done. 46.406694650650024 total seconds elapsed\n",
      "importing rows 19000000 to 20000000...Chunk Done. 46.90617632865906 total seconds elapsed\n",
      "importing rows 20000000 to 21000000...Chunk Done. 45.84269165992737 total seconds elapsed\n",
      "importing rows 21000000 to 22000000...Chunk Done. 45.69237971305847 total seconds elapsed\n",
      "importing rows 22000000 to 23000000...Chunk Done. 46.54261040687561 total seconds elapsed\n",
      "importing rows 23000000 to 24000000...Chunk Done. 46.691495180130005 total seconds elapsed\n",
      "importing rows 24000000 to 25000000...Chunk Done. 46.344937562942505 total seconds elapsed\n",
      "importing rows 25000000 to 26000000...Chunk Done. 46.07554221153259 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Chunk Done. 1.1272096633911133 total seconds elapsed\n",
      "Done. 1272.0166971683502 total seconds elapsed for entire upload.\n"
     ]
    }
   ],
   "source": [
    "# create SQL table for movies_df\n",
    "connection = F\"postgresql://postgres:{password}@127.0.0.1:5432/Movies_Data\"\n",
    "engine = create_engine(connection)\n",
    "movies_df.to_sql(name='movies', con=engine, if_exists='replace')\n",
    "\n",
    "# create table for ratings_df\n",
    "rows_imported = 0\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(ratings_file, chunksize=1000000):\n",
    "    round_time = time.time()\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='replace')\n",
    "    rows_imported += len(data)\n",
    "    print(f'Chunk Done. {time.time() - round_time} total seconds elapsed')\n",
    "\n",
    "print(f'Done. {time.time() - start_time} total seconds elapsed for entire upload.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
